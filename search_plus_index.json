[{"url":"./","title":"实验简介","level":"1.1","keywords":[],"body":"数据库系统概论实验 本文档为《数据库系统概论》大作业实验文档，于 2021 年暑假开始编写，并计划于接下来几年内不断完善。 文档志在通过 step-by-step 的模式引导选课同学（或其他有兴趣的同学）完成一个 demo 级别的数据库管理系统。 如果你发现了任何章节的纰漏，欢迎通过该文档下方的评论区指出。 本文档最后发布于 2021/9/9 21:28:47。 "},{"url":"chapter-0/intro.html","title":"0.1 概述","level":"1.2.1","keywords":[],"body":"0.1 概述 本文档假定同学们已经具备了基本的 SQL 知识，因此内容将重点放在数据库引擎开发上。我们的数据库系统架构如图所示： 其中： 其中用户部分还涉及到交互问题，这将在《0.3 前端约定》一节中提到。 命令解析器将随文档一并提供，我们统一使用 ANTLR4 来作为解析工具，详见第五章相关内容。 页式文件系统及其缓冲区有一份“祖传实现”，但我们也在第一章提供了编写指引，愿意的话可以自行实现。 记录管理模块、索引模块、查询解析模块、系统管理模块是实验的主要内容。 last update at: 2021/9/7 20:42:36 author: 饶淙元 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-0/backend.html","title":"0.2 后端约定","level":"1.2.2","keywords":[],"body":"0.2 后端约定 为了便于后续部分模块介绍，我们假定一个场景以便举例之用。 数据库 参考清华大学课程系统，我们简化出一个简单的模型，包含学生、教师、课程、（同一课程号的）课程的不同开课信息、学生选课信息等表。 首先我们创建一个数据库 curriculum： CREATE DATABASE curriculum; 实际使用时还应该用到数据库切换指令 USE curriculum; 上述指令属于系统管理指令，但我们的实验文档是按照自下而上的顺序搭建系统，因此在实验前中期你可能更需要关注下面的数据表。 数据表 首先学生 (student) 和老师 (teacher) 有对应的编号 (id)、姓名 (name)、性别 (sex)，此外同学有一个字段身份 (status) 区分本科生、硕士生、研究生。 CREATE TABLE student ( id INT NOT NULL PRIMARY KEY, name VARCHAR(32) NOT NULL, sex VARCAHR(4), status VARCHAR(32) NOT NULL ); CREATE TABLE teacher ( id INT NOT NULL PRIMARY KEY, name VARCHAR(32) NOT NULL, sex VARCHAR(4), ); 每门课程 (course) 有唯一的课程号 (id)、课程名 (name)、学分 (credit)。由于同一门课可以由不同老师开设（或同一老师的不同时段）并有不同的课程介绍 (description)，这用课序号 (course_number) 进行区分，我们将这些信息的集合称作一个课程详情 (course_detail)。 注意 course_detail 使用了复合主键 (course_id, course_number)。 CREATE TABLE course ( id INT NOT NULL PRIMARY KEY, name VARCHAR(32) NOT NULL, credit INT DEFAULT 0 ); CREATE TABLE course_detail ( course_id INT NOT NULL, course_number INT NOT NULL, teacher_id INT DEFAULT NULL, description VARCHAR(4096), PRIMARY KEY (course_id, course_number), FOREIGN KEY (course_id) REFERENCES course(id), FOREIGN KEY (teacher_id) REFERENCES teacher(id) ); 最后，一位同学的选课信息 (student_course) 需要添加成绩 (grade)、学期 (term) 信息。注意它有复合主键 (student_id, course_id, term)，这暗示着一门课在一个学期只能被一名同学选一次（更多的时候一名同学只能选一门课一次，但这不由数据库保证），(course_id, course_number) 构成了复合外键指向 course 的复合主键。 CREATE TABLE student_course ( student_id INT NOT NULL, course_id INT NOT NULL, course_number INT NOT NULL, grade VARCHAR(3), term VARCHAR(16) NOT NULL, PRIMARY KEY (student_id, course_id, term), FOREIGN KEY course_id_number(course_id, course_number) REFERENCES course_detail(course_id, course_number), FOREIGN KEY (student_id) REFERENCES student(id) ); [info] 主键数据类型 主键会带索引，在我们实验要求中仅对整型索引做要求，因此主键一定是整型或其组合。 上述复合主键 (student_id, course_id, term) 中的 term 是 VARCHAR，这仅用于举例。 last update at: 2021/9/9 13:40:37 author: 饶淙元 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-0/frontend.html","title":"0.3 前端约定","level":"1.2.3","keywords":[],"body":"0.3 前端约定 前端含义 首先本节标题中的“前端”不是指 GUI，而是指我们设计的系统（更像是一个引擎）与人交互时所提供的输入输出形式。 在往年（即本文档诞生之前）的实验中并没有明确要求输出格式，验收也采用手动测试、“能看就行”的原则，助教仅额外要求了输出总行数以便检查。输入方面同样也没有给出足够具体的要求，例如是否需要支持多行输入，分号隔开的多语句输入等。最终同学们作业大多呈现为 CLI 下的单行输入、| 等符号作为列分隔符的多行输出。 现在我们希望能够在这方面进行一定的规范，以便手动检查和将来可能会到来的自动化测试。我们将手动检查时的模式称作“交互模式”，将面向自动化测试的模式称作“批处理模式”。 运行模式 1. 交互模式 交互模式可以参考 MySQL 的模式，如下是一个示例 MySQL [curriculum]> SELECT * FROM student; +------------+--------+-----------+------+ | id | name | status | sex | +------------+--------+-----------+------+ | 2077310001 | 王五 | 博士生 | 男 | | 2077010001 | 张三 | 本科生 | 男 | | 2077210001 | 李四 | 硕士生 | 男 | +------------+--------+-----------+------+ 3 rows in set (0.000 sec) MySQL [curriculum]> SELECT COUNT(*) -> FROM -> student -> -> ; +----------+ | COUNT(*) | +----------+ | 3 | +----------+ 1 row in set (0.000 sec) MySQL [curriculum]> 交互模式不给出严格的要求，主要为了便于自己调试以及助教检查。仿照 MySQL 的 shell，以下给一些可选地参考实现细节： 输入时在左边给出前缀并给出当前的数据库名 跨行输入时给出规整前缀（无需考虑“修改上一行”的操作） 输入在最后一个字符是 ; 后停止 尝试画表格边框以提高美观度 尝试计算出一列的最大宽度后输出时用空格补齐以保持规整 在输出表格后面给出行数和后端查询时间 2. 批处理模式 批处理模式下我们不在乎输入输出的友好性，通常是从 stdin 或者一个 SQL 文件读入多行数据，再输出到 stdout 或一个指定文件。在使用 stdin 和 stdout 时常常搭配重定向。 批处理模式下的输出就如同做 OJ 一般不能夹带任何冗余信息，必须按照约定的格式给出数据，常见格式是用 tab 分隔符，如 MysQL 等成熟的数据库系统会支持包括 CSV、JSON 在内的多种输出方式自选。 方便起见我们为批处理模式做出如下约定： 输出统一使用的 CSV 格式的子集：同一行的不同字段间用英文逗号 , 分隔，无需考虑数据包含逗号的二义性问题。； 浮点数输出为两位小数； 无需考虑非 ASCII 字符的编码及长度问题，最终测试可以假定全是 ASCII 可打印字符（你自行测试时它很可能是由你终端的设置决定）； 不考虑语法错误、破坏完整性约束等输入错误的情形（对应内容的检查会在交互式模式下进行）； 使用命令行可选参数 -b 表示以批处理模式启动； 使用命令行可选参数 -d <database> 指定数据库名，即相当于已经执行了 use <database>;。 TODO: 这里还需要约定表头的写法（或者干脆不输出表头），尤其是列名前要不要带表名，以及一些聚合查询、系统管理语句的表头。 数据导入 考虑到部分同学实现大量 INSERT 时效率并不高，为了完成压力测试，我们需要新增一种操作将（被认为是安全的）数据直接导入数据库。 往常没有统一约定读入指令或参数，现在统一约定如下： 数据导入需要在批量模式下进行，且必须指定数据库； 使用命令行可选参数 -f <path> 指定导入文件的路径； 使用命令行可选参数 -t <table> 指定目标表名； 在上述约定下，假设我们编译得到的可执行程序是 mydb，则可以通过类似如下语句进行数据导入 ./mydb -b -f path/to/data/student.txt -t student -d curriculum 数据格式则同批量模式输出一样采用 CSV，这里我们直接约定字符串中不会出现 ,，因此可以很方便地手动解析。 desc 往年实验没有为 desc <table_name> 的指令给出详细的内容要求，这里我们给出如下要求： TODO: 待商议 last update at: 2021/9/9 13:40:37 author: 饶淙元 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-1/intro.html","title":"1.1 文件管理模块概述","level":"2.1.1","keywords":[],"body":"1.1 文件管理模块概述 引言 这个模块属于是数据库的底层设施，甚至不算数据库的一部分，它的全名叫《页式文件管理系统》，是一个管理文件及其缓存的系统。在课改前的大作业中是没有算进需要实现的几个模块之一的，但助教商讨认为，了解本模块对于理解数据库的上层实现有重要意义，因此我们依然提供了往年祖传的实现（后文简称“参考实现”，可从文档的《附件》章节中下载），但也进行了详细讲解，以便有需要的同学按照教程自行实现。 需求 首先需要理解我们为什么需要数据库，为什么需要一个专用的文件管理系统。 1. 大文件 数据库被设计用来存储大量数据（通常是高于计算机内存的）并进行增删查改等操作，我们在操作时内存通常只能取数据库文件的一小部分进行局部操作。 尽管我们不必将一个数据库存在一个文件中，也即我们可以通过将不同表拆分成不同文件、将数据和索引拆分成不同文件等手段来减小文件的大小，但一般至少一张表的数据会存入同一个文件中，我们仍然可能因为一张表有上G条记录而出现超过内存大小的文件。 2. 页式管理 因此我们需要一种策略将数据库的文件拆分成更小的单元，将文件操作体现在这些单元之上。因此，首先我们需要一个页式文件系统，将文件以页为单位进行拆分——页的大小不必是一样的，但是简单起见我们实现的是固定页大小的。本文档中还会提到页的概念，如无特别解释均指代页式文件系统的“页”，它的大小或许恰好与操作系统的页相同，或许不同，需要注意区分。 3. 缓存引入 完成页式文件系统后，我们需要操作的成本问题： 一方面，我们不能在每次读写时都去文件中获取一页，IO 时间会有较高成本，我们希望通过更多的 CPU 计算来减少 IO 频次，提高数据库引擎性能，在文件较小时，针对这一问题有一种经典的减少 IO 操作法（维护一些 meta 信息时仍然可以参考这种手段）：启动程序时（或者第一次读写时）将文件内容全部读入内存，操作完毕后在结束程序时（或者其他合适的时机，但保证频率应该较低）将文件内容写回文件。 但在另一方面，即便页式处理后，由于无法看见文件的全貌，我们一定会因为内存不足而需要交换内存和文件的页，因此不能像处理小文件那样借助内存将 IO 完全降低为一次读一次写。 综上所述，我们需要合理使用内存作为文件系统的缓存，如果你了解 CPU 的缓存策略会发现它们有极高的相似之处。我们需要事先在内存中预留好若干页的空间，并为每个页准备一些额外属性，例如 dirty 标记、对应的文件页位置等，我们将在后面的章节讲述缓存替换算法。 相关组件 我们需要这样一些组件来完成上述的文件管理： 一个完成文件 IO 的管理器，它会处理文件创建、打开、删除，完成一页数据的读、写（对应参考实现的 FileManager） 一个容器来存储已经打开过的文件，并暴露一个 ID 或者对象供上层使用（对应参考实现的 FileManager::fm） 相关 IO 接口调用，包括二进制文件打开（及创建）、关闭、偏移到指定位置并读写指定大小（对应参考实现的 open、close、lseek、read、write 等） 一个为数据页提供缓存的缓存管理器，它对外提供提供指定文件读写，内部根据实际情况操作缓存数据（对应参考实现的 BufPageManager） 一个大数组（内存块）来存放大量页（对应参考实现的 BufPageManager::addr，注意它配合 BufPageManager::allocMem 使用了二维动态数组，但这对性能可能并不友好） 上述内存块的元信息，记录对应的文件、页号、dirty 标记等，判断是否命中缓存及对应数据的位置（对应参考实现的 BufPageManager::hash 和 BufPageManager::dirty） 一个缓存替换算法，未命中缓存时决定将新的缓存页放在哪（对应参考实现的 BufPageManager::replace 配合 BufPageManager::last） 本章剩下几节将给出完成这些组件的文档。 last update at: 2021/9/9 20:49:25 author: 饶淙元 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-1/page.html","title":"1.2 页式文件系统设计","level":"2.1.2","keywords":[],"body":"1.2 页式文件系统 总述 首先大前提是我们采用的二进制文件而非文本文件作为数据库文件的存储形式，下面需要考虑数据将以何种形式写入二进制文件。我们可以将文件按照固定大小拆分，从而磁盘上的文件读写都以这样的大小作为最小单元，我们将这样的最小单元称作“一页”。一般来说出于对齐等考虑，页的大小会设计成 2 的次幂数，我们在本章以 8192 字节为例（参考实现中也采用了这个大小）。 如果已经确定了页式，那么文件在我们眼中将从一个很大的字节数组变成若干页，我们将不再使用一个字节的位置来访问数据，而是使用 (页号, 页内偏移) 的二元组。例如 (6, 66) 表示文件内下标为 6×8192+66=49218 6 \\times 8192 + 66 = 49218 6×8192+66=49218 的字节。 我们应该尽量在一页之内读写数据，即尽量避免一条记录跨越两页的情况。这不可避免地会导致一些空间上的浪费，例如一页 8192 字节，我们使用了 8190 字节后想再插入一条 10 字节的记录，那么应该直接考虑下一页而非将它拆成 2 + 8 字节放在两页中。此时空出来的 2 字节就是一种空间碎片，但所幸它的比例非常小，在这种情况下我们的空间利用率可以达到 8190÷8192=99.98 8190 \\div 8192 = 99.98% 8190÷8192=99.98 ，这已经足够高。 当文件已有页不够用时，我们会在末尾再新加一页，因此文件的大小将始终是 8192B 的倍数。 记录槽位 大体上我们可以将页分为数据页和索引页，前者用于存记录，后者用于存索引。这两种数据页类型并不需要在页式文件系统里体现出来，作为一个底层系统它只负责为上层提供页式的接口，但是我们有必要站在更上层的角度来看看页式系统到底起到了什么样的作用。 以后端约定章节的 student 表为例，它的字段（列）有一个 id INT，一个 name VARCHAR(32)，一个 sex VARCHAR(4)，一个 status VARCHAR(32)。INT 自然是 4 字节，因此如果假定没有其他数据，将各个字段按固定顺序和大小紧密地放在一起，就会有 72 字节。 假设一个人 id 为 2077010001，姓名 张三，性别 男，身份 本科生，汉字采用 UTF-8 编码（这几个汉字均为三字节），那么对应的记录可能如下所示（最下方一行表示编码得到的字节，低地址在左高地址在右） 学号 姓名 性别 身份 2077010001 张三 男 本科生 51 A8 CC 7B E5 BC A0 E4 B8 89 00 00 00 ... 00 E7 94 B7 00 E6 9C AC E7 A7 91 E7 94 9F 00 00 00 ... 00 注意这里我们假定使用定长字符串存储字符串，因此多出来的部分补充了大量的 0 （用 ... 省略），实际上如果实现了变长字符串可以避免这种浪费，但另一方面可能会额外需要一些空间存储字符串长度。 因此最终得到的 72 字节的一条记录如下所示： 51 A8 CC 7B E5 BC A0 E4 B8 89 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 E7 94 B7 00 E6 9C AC E7 A7 91 E7 94 9F 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 假设该表每条记录均用这样的定长 72 字节记录，那么一页至多能存 ⌊819272⌋=113 \\lfloor \\frac {8192} {72} \\rfloor = 113 ⌊728192​⌋=113 条记录，剩余 56 字节，这 56 字节中的 ⌈1138⌉=15 \\lceil \\frac {113} {8} \\rceil = 15⌈8113​⌉=15 字节正好可以用来维护一个 bitmap 表示一条记录的位置是否被占用了。剩余 41 个字节可以用于指向下一页等页面元信息。 在上述约定下，一页中至多可以存 113 条记录，即使还没有插入记录，这些空间也已经被分配了，但是我们会用上述的 bitmap 暗示它们没有存有效数据，这种被预分配出来等待一条记录插入的位置称为槽 (slot)。一页空间被分为若干槽、记录槽状态的 bitmap 以及页面元信息。 页面空间的具体使用将在下一章记录管理模块详细介绍，下面来讨论下具体实现需要的工具。 [warning] 一条记录的组成 尽管在上述例子里我们将一条记录设计成了其字段的连续堆积，但实际上也可以将定长改为变长，或者按行存储改为按列存储等。此外我们的数据库需要支持 NULL，因此还需要考虑其表示等。另外在一些常用数据库如 MySQL 中 VARCHAR 也不是单字节而是宽字符，上述例子仅仅是一个简单示意，页内数据的组织参考下一章记录管理模块的相关内容。 底层接口 那么要实现页式文件操作需要用到哪些底层接口呢？我们需要的操作包括： 创建文件：数据库最初可能空无一物，记录一定是从新建一个新文件开始 打开文件：以读写混合模式打开文件以进一步读写文件 关闭文件：关闭文件后操作系统会刷新文件缓存等，真正的磁盘访问或许发生在这一步，但这对我们透明 删除文件：尽管你的系统也可以通过一些 trick 避免删除文件，但是删除文件（夹）本身是很有必要的，例如删除数据表、索引、数据库时 文件偏移：我们需要偏移到某一页开头的位置，以便接下里读取一页或写入一页 数据读取：需要允许我们将一页的数据一次性从文件读取到内存（此前理应已经完成了偏移设定） 数据写入：需要允许我们将一页的数据一次性从内存写入到文件（此前理应已经完成了偏移设定） 上述操作对你来说不一定会感到自然，尤其是如果你此前的文件操作多为文本文件读写，可能会很不适应。但是在二进制文件读写时，这些是非常常见的底层操作，无论你用何种常见语言（如 C、C++、Java、Python、Go、Rust 等），用操作系统的接口还是语言标准库提供的接口，都应该能找到上述功能对应的接口。 [info] 创建 & 打开文件 实际上很多语言/系统中创建与打开文件使用了同一接口，这主要是因为在常见接口中用只写 (Write Only) 方法打开文件本身就会起到删除原有文件、创建新文件的效果。不同实现方可能为这些接口起的名字很不相同（例如 Windows API 中使用 CreateFileA），需要查询相应文档以理解其使用方式。 在部分笔者了解的语言/系统上对应的函数如下： 操作 Linux / Unix C (stdio) C++ (STL) 创建文件 open fopen fstream::open 打开文件 open fopen fstream::open 关闭文件 close fclose fstream::close 删除文件 unlink / rmdir remove filesystem::remove 文件偏移 lseek fseek fstream::seekp / fsteam::seekg 数据读取 read fread fstream::read 数据写入 write fwrite fstream::write [warning] 跨平台实现 参考实现使用了 Linux/Unix 接口（<fcntl.h> 与 <unistd.h> 库中的函数），因此在 Windows 上无法使用。如果选择使用 C 或 C++ 的标准库能够（或许会付出性能代价）使你的程序支持跨平台，这本质上是标准库为你封装了不同操作系统的接口。我们的大作业原则上不对操作系统做要求，但是我们仍然建议你的程序能够支持 Linux，因此最好不要用 Windows 或 Mac 系统的接口。 由于你使用的文件操作库不同，因此文件操作所暴露出的东西也不同，例如 Windows 接口会得到句柄，Linux 接口会得到 fd 号，C 接口会得到 FILE 指针等，我们建议将这些东西存在文件管理器内，对外暴露一个统一的文件号，可能对应内部的数组下标或一个 map 的 key 等。在这种实现下你可以考虑将允许的文件号组成令牌环之类的结构，也可以不限制数量，用一个 map 来存储全局单增的文件号（我们可以不考虑在一次运行中累计开关几亿个文件导致文件号溢出的情况）。参考实现比较特殊，采用了 map + 令牌桶的组合形式 MyBitMap，实际容量为 128（可调），即至多允许同时打开 128 个不同的文件。 但另一方面，你也可以考虑直接让上层系统通过文件名加页号来访问数据，这种设计下上层系统甚至不需要打开文件的操作，直接读取某文件内容，让文件系统自己来判断是否需要打开操作。在我们给出的 API 文档中给了接口的重载形式，可以选择性实现与使用。 对外接口 无论你选择以何种语言、设计模式、命名风格，我们都应设计以下对外接口来供上层系统使用： CreateFile: 创建文件，对应参考实现中的 FileManager::createFile OpenFile: 打开文件，对应参考实现中的 FileManager::openFile CloseFile: 关闭文件，对应参考实现中的 FileManager::closeFile RemoveFile: 删除文件，参考实现中未实现该功能 ReadPage: 读取文件中指定一页，对应参考实现中 FileManager::readPage WritePage: 写入文件中指定一页，对应参考实现中 FileManager::writePage 附录 探讨页式文件系统时会涉及到一些常用的2的次幂数以及通用符号： 210=1024=1k=1K212=4092213=8192220=210k=1m=1M230=210m=1g=1G1Byte=1B=8bit=8b−231=−2147483648≤int32≤231−1=2147483647 2^{10} = 1024 = 1k = 1K \\\\ 2^{12} = 4092 \\\\ 2^{13} = 8192 \\\\ 2^{20} = 2^{10} k = 1m = 1M \\\\ 2^{30} = 2^{10} m = 1g = 1G \\\\ 1 Byte = 1 B = 8 bit = 8b \\\\ -2^{31} = -2147483648 \\le int32 \\le 2^{31} - 1 = 2147483647 210=1024=1k=1K212=4092213=8192220=210k=1m=1M230=210m=1g=1G1Byte=1B=8bit=8b−231=−2147483648≤int32≤231−1=2147483647 注意 k、m、g 这些字母通常不区分大小写，但是常常会跟在它们后面的 b/B 则会区分带小写，前者是比特 (bit)，表示 0/1 二进制位，后者是字节 (Byte) 表示八个二进制位，可以用于编码 -128 到 127 的符号整数或 0 到 255 的无符号整数。 last update at: 2021/9/9 19:00:09 author: 饶淙元 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-1/buffer.html","title":"1.3 LRU 缓存设计","level":"2.1.3","keywords":[],"body":"1.3 文件缓存管理 功能总述 在上一节中我们已经拥有了页式文件系统的底层支持，但单有它还不足以称作一个完整的系统设计，因为在现有接口下我们只是一次读取一页（如果有需要的话）再写回，频繁地文件操作仍然会带来高昂的成本。现在到了该给系统设计一个缓存的时候了！ 我们的缓存本身需要能存储若干页，在参考实现中取的 60000 页，这里我们沿用这一设定，但我强烈建议把它放在某个可以方便地配置的位置（编译时或运行时皆可），以便将来有需要时调整大小。尽管还没有讲细节，但你应该意识到，在一定范围内，缓存准备的页数越多，理论上性能会越高。 我们的缓存系统需要供上层系统直接访存读写指定页用，上层系统需要读写一页时它需要提供以下功能： 需要目标页是否在缓存中： 目标页在缓存中，直接读写内存中的副本 目标页不在缓存中，需判断是否仍有空闲页： 若有空闲页，从文件中获取一页并置入一个空闲页，然后在内存完成读写 若无空闲页，则需先舍弃缓存中一页，再从文件中获取一页并置入刚刚舍弃出的空位，然后在内存完成读写 这里涉及到两个问题，写入时机与置换策略。 写入时机 文件读取不会改变文件自身，因此并不复杂，但是涉及到写入时数据会发生双向流动：从文件到缓存，再从缓存到文件。后者的操作时机是一个值得斟酌的问题。 1. 写直达 (Write-Through) 我们可以只用内存来缓存读取，所有的写入均直接写到磁盘上，这种策略称作写直达，它的性能比不上下面介绍的写回，但是它的实现相对简单，在某些特殊的硬件缓存上可能会考虑这一策略来保证硬件逻辑的简洁性。但是在我们这种内存与磁盘性能差异以及 CPU 性能下，一般不会考虑这一策略，尤其是对局部数据频繁 UPDATE 或先 DELETE 再 INSERT 时它的性能会非常差。 2. 写回 (Write-Back) 写回策略在更多缓存系统中被使用，它一般配合 Dirty 位一并使用。无论是读还是写，我们总是需要先从文件中获取该页数据到内存，然后所有写入均在内存中直接操作，当该页缓存被舍弃（或者文件被关闭等）时再将缓存中的变化写回到文件中。 出于性能考虑，我们不应该将所有被舍弃的页均写回文件，因为其中可能有很多页只发生了读，没有被写过。为了区分被写过的页，我们引入 Dirty 标记位，当一页缓存被写入时，我们将对应的 Dirty 标记置为 True（一般将这种页面称作“脏页”），当该页被舍弃时，可以根据 Dirty 判断是否需要将写回文件。 置换策略 当缓存页被占满时，我们为了新的缓存页不得不放弃原有的一页，此时需要一个策略来决定放弃哪一页。 在介绍置换策略时，这些策略并非针对页式文件系统，而是这类缓存置换问题的通用算法，因此下面介绍算法时将不再提到“页”，而是直接用“数据项”来指代任何缓存系统中的目标数据。 [info] 决策内容的思考 除了占满时决定放弃谁外，即使缓存没被占满，我们或许也需要一个策略来判断应该用哪一个空位。这个问题或许并不重要，因为对多数策略来说用哪一个缓存页是无关紧要的。但如果再考虑到 CPU 本身的缓存，选择一些近期刚被舍弃的缓存页可能会给性能带来一定幅度的提升。 下面介绍几种基础的缓存置换算法（推荐使用 LRU，实现简单且有不错的性能，你也可以选择自己喜欢的策略）。 1. LRU LRU (Last-Recently-Used) 即最近最少使用算法，是一种非常常见的缓存置换算法。它按照使用次序，将最后使用时间较久远的数据先替换掉。 [info] LRU 名字解读 “最近最少使用” 对部分同学来说可能有些拗口，可以根据英文这样来理解它： Recently Used 为我们的数据定义了一个顺序，按照最近被使用的时间排序，最近使用的一项为首项 (first) Last 指上述排序后末尾的一项，也即使用时机距今最远的一项 例如，假设我们有一个容量为 3 的存储整数的缓存，我们依次访问数据序列 1 2 3 3 3 1 4 4 4 2 1，那么缓存的变化如下所示： 访问数据 缓存命中 舍弃缓存项 （访问后）缓存内容 1 F _ [ 1 ? ? > 2 F _ [ 2 1 ? > 3 F _ [ 3 2 1 > 3 T _ [ 3 2 1 > 3 T _ [ 3 2 1 > 1 T _ [ 1 3 2 > 4 F 2 [ 4 1 3 > 4 T 2 [ 4 1 3 > 4 T 2 [ 4 1 3 > 2 F 3 [ 2 4 1 > 1 T _ [ 1 2 4 > 共计访存命中 6 次（如果用下面的 LFU 则是 5 次）。 为了高效实现这样的效果，可以考虑使用一个环形链表，将所有数据项在缓存中的编号连成一个链表。当某项被访问时将对应结点置为首项；当需要将新的数据项置入缓存时总是置入链表尾项结点对应的编号项并将其置为首项，如果该项已被占用则需先舍弃原来的数据项并处理可能的写回。在这种策略下，置换策略的相关操作复杂度均为 O(1)。 2. LFU LFU (Least-Frequently-Used) 即最不经常使用法，这个方法需要记录所有数据项的访问频率（频次），将访问最少的数据项舍弃。 这里给出一个简单的例子，使得 LFU 性能比 LRU 好。仍然假设容量为 3 的存储整数的缓存，我们依次访问数据序列 1 1 2 3 4 1 5 6 7 1，缓存变化如下所示： 访问数据 缓存命中 舍弃缓存项 （访问后）缓存内容 1 F _ 1(1) ?(0) ?(0) 1 T _ 1(2) ?(0) ?(0) 2 F _ 1(2) 2(1) ?(0) 3 F _ 1(2) 2(1) 3(1) 4 F 2 1(2) 4(1) 3(1) 1 T _ 1(3) 4(1) 3(1) 5 F 3 1(3) 4(1) 5(1) 6 F 4 1(3) 6(1) 5(1) 7 F 5 1(3) 6(1) 7(1) 1 T _ 1(4) 6(1) 7(1) 注意到后 3 次访问 1 均会命中缓存，但若用 LRU 则只能命中一次缓存。 这种方法会维护全局计数信息，某些情况下效果确实不错，但是也有一些显著问题： 可能需要维护斐波那契堆之类的较复杂结构来支持访问最小项以及任意项更新 当有多个低频次并列时，算法本身并没有给出确定性的替换对象，而这种 case 可能被一些特定的场景放大导致它无法起到预想的作用 算法没有“局部性”，全局的频次统计可能导致某小段内被大量访问的数据可能被长久记忆——即使这些数据早已无人问津 因此这一策略在实际应用中并不常见。 3. FIFO FIFO (First-In-First-Out) 即先进先出，只需要维护一个队列，只考虑数据项入队的时间，当队列满时将最早入队的元素出队。 下面构造一种简单情况使得 FIFO 的性能比 LRU 和 LFU 好。同样假设容量为 3 的存储整数的缓存，我们依次访问数据序列 1 2 3 1 4 5 3，缓存变化如下所示： 访问数据 命中缓存 舍弃缓存项 （访问后）缓存内容 1 F _ [ 1 ? ? > 2 F _ [ 1 2 ? > 3 F _ [ 1 2 3 > 1 T _ [ 1 2 3 > 4 F 1 [ 2 3 4 > 5 F 2 [ 3 4 5 > 3 T _ [ 3 4 5 > 共计缓存命中 2 次，如果用 LRU 或者 LFU 均只能命中一次。 FIFO 实现简单，只需要一个最基本的队列，但是可能会导致频繁访问项被舍弃，并且存在 Belady 现象，实际应用并不广泛。 [info] Belady现象 使用 FIFO 等算法时，可能出现在相同的访存序列下，缓存容量增大后，缓存缺失次数反而升高的异常现象。 感兴趣的同学可以自行构造这样的例子，《操作系统》课程中也会讲到相关知识。 系统组装 有了上述基础，我们下面完成一个缓存管理器（参考实现的 BufPageManager）只需要一些组装。它底层依赖一个页式文件系统管理器（参考实现的 FileManager）和一个缓存置换器（参考实现的 FindReplace）。 它对外提供的接口与页式文件系统基本一致，只是需要考虑是真的要调用文件系统，还是直接进行内存操作。注意写操作可能有两种实现办法： 不提供单独的写入接口，对外的读取接口返回缓存的引用，外部修改时需要手动调用缓存管理器的接口将对应页标记为 dirty 提供单独的写入接口，对外的读取接口返回的是一页的拷贝，缓存中给的数据独此一份，调用写接口时会用传进来的数据覆盖原有的缓存页并标记 dirty 前一种实现性能更高，但是用起来也有更高的风险；后一种更直观，但是会引入拷贝一页的成本。无论是哪一种实现，均是基于写回策略。 在参考实现中，采用的上述第一种方案，因此它还为缓存管理器提供了以下接口： close: 关闭管理器，将所有脏页写回文件（个人建议写入析构函数） writeBack: 将指定页面写回并舍弃 release: 将指定页面舍弃，即使是脏页也不写回 access: 标记一页被访问过 markDirty: 标记一页为脏页 allocPage: 越过查找缓存直接进行文件 IO，需要调用方保证该页不在缓存 last update at: 2021/9/9 19:00:09 author: 饶淙元 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-1/api.html","title":"1.4 对外提供接口","level":"2.1.4","keywords":[],"body":"1.4 对外提供的接口 typedef int FD; typedef char *BufferType; class FileManager { public: FileManager(); ~FileManager(); // 下面的 BufferType 可以自行考虑具体实现，但是内存管理上最好由缓存系统管理而非文件系统 void createFile(string filename); FD openFile(string filename); void closeFile(FD fd); void removeFile(string filename); void readPage(FD fd, int pageID, BufferType buffer); void writePage(FD fd, int pageID, BufferType buffer); // 文档提到的另一种思路，上层系统直接传文件名 void closeFile(string filename); void readPage(string filename, int pageID, BufferType buffer); void writePage(string filename, int pageID, BufferType buffer); }; class BufferManager { public: BufferManager(); ~BufferManager(); // 这里只展示用 FD 的方法，如果采用文件名直传，则所有 FD 都可以改为文件名 // 这些文件操作不一定需要，也可以实现成上层传文件名，底层自动处理打开、创建 // 如果实现则直接调用 FileManager 的操作 void createFile(string filename); FD openFile(string filename); void closeFile(FD fd); // 是否需要删文件的接口取决于你的系统实现 void removeFile(string filename); // 1. 如果采用读引用的方法，则可以参考这两个接口，读写用的 buffer 空间由底层管理 BufferType readPage(FD fd, int pageID); void markDirty(FD fd, int pageID); // 2. 如果采用读拷贝的方法，则可以参考这两个接口，读写用的 buffer 空间由上层管理 void readPage(FD fd, int pageID, BufferType buffer); void writePage(FD fd, int pageID, BufferType buffer); }; last update at: 2021/9/9 19:00:09 author: 饶淙元 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-2/intro.html","title":"2.1 记录管理模块概述","level":"2.2.1","keywords":[],"body":"2.1 记录管理模块概述 数据库文件布局 可以在根目录下创建base和global两个目录：global目录中存储一些全局的系统表，如：数据库名和数据库ID的对应关系 (pg_database)。在base目录中，每个数据库对应一个子目录，子目录下也可以有一些系统表，如：关系 (包括表、索引) 名和关系ID的对应关系 (pg_class)。子目录下的表和索引都存储在单独的文件中，子目录和文件都以其ID命名。 文件的组织结构 为提高存储空间利用效率和管理的灵活性，文件被划分为页面 (如固定大小为4KB) 的集合，每个页面有唯一的标识符。页面的数据区被划分为一个个插槽，每个插槽中放置一条记录。这样，(文件路径，页号，槽号) 就与记录构成了一一对应的关系。某条记录的页号和槽号建议不要轻易修改，否则相关的索引也要修改。 表的元数据 表的元数据包括表的列数、各列的数据类型和长度、表的页数、约束 (检查约束、唯一约束、主键约束、外键约束) 等信息，可以在数据库目录下创建系统表存储 (参考PostgreSQL的系统表)，简单的话也可以存储在表的前几页。 记录相关操作 记录的序列化和反序列化。在字节序列和一条记录间相互转换。 访问记录。根据数据库名和表名确定文件路径，根据页号和槽号找到记录的位置，通过反序列化解读出记录的内容。 插入记录。先找到空闲空间，再插入记录的序列化表示；如果没有空闲空间可能需要向缓存管理模块申请新页。 删除记录。先找到记录的位置，再将其删除；产生的碎片空闲空间视情况合并。 更新记录。对于定长记录来说，物理组织结构不变；对于变长记录来说，与删除后插入类似。 一些测试相关的要求 我们要求的数据类型包括INT, FLOAT, VARCHAR(i)三种。其中INT为32位整型，FLOAT为单精度浮点型，VARCHAR为字符串，且用括号中的 i 表示字符串最大长度。在实际数据库中，VARCHAR会作为变长列存储，占用空间由具体字符串的实际长度决定；同学们在实现时将其作为定长列或变长列存储均可。 在基础功能中，我们限定一条记录的各列最大长度之和不会超过2048字节。我们希望保证一页至少能完整地存储一条记录。 last update at: 2021/9/9 13:31:51 author: 孙昭言 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-2/fixed.html","title":"2.2 记录页面的设计模式-定长记录","level":"2.2.2","keywords":[],"body":"2.2 记录页面的设计模式-定长记录 记录存储格式 对于定长记录来说，记录的各列属性具有固定的长度，所以可以通过 (NULL位图, 各列数据) 的方式储存。以0.2提到的course表为例： NULL位图 (1B) id (4B) name (32B) credit (4B) NULL位图长度为 ⌈列数/8⌉ 字节，即每列一位储存该列是否为空。在解读时，记录的列数以及各列长度属于表的元数据。 页面布局 可以将页 (如：4KB) 划分为页头 (如：64B) 和数据两部分，后者可以按照记录长度划分为一个个槽,并在页头使用位图储存每个槽是否空闲。在插入记录寻找空闲槽时，只需要对位图进行处理；在删除记录时要对位图进行维护。在根据槽号访问记录时还需要记录的长度，该信息可以存储在页头，也可以由表的各列长度计算得到。 空闲空间管理 由于记录长度固定，所以只需要区分页面是否有空闲槽即可。可以维护两个链表分别由空闲页和满页组成，邻居页号可以在页头中存储，链表头页号可以作为表的元数据存储。 last update at: 2021/9/9 13:31:51 author: 孙昭言 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-2/variable.html","title":"2.3 记录页面的设计模式-变长记录","level":"2.2.3","keywords":[],"body":"2.3 记录页面的设计模式-变长记录 记录储存格式 可以以按照 (NULL位图, 定长数据, 可变列的偏移数组, 变长数据) 的格式存储变长记录。以0.2提到的course表中 (30240262, 'Database', 2) 的一行为例： 0 (1B) 30240262 (4B) 2 (4B) 19 (2B) 'Database' (8B) NULL位图和定长数据部分与定长记录相同；可变列偏移数组的长度为 2字节*可变列数，从而在变长部分区分出各可变列的数据。在本例中，19为第一个变长列结束的位置。由于其也是最后一个变长列，所以19也表示本行的长度。 页面布局 页头需要存储槽容量 (有效槽+无效槽总数) 辅助解读页面字节序列，还需要存储空闲空间的字节偏移量和空闲字节数目便于空闲空间管理。解读页面还需要定长部分 (NULL位图+定长数据) 长度、可变列数目等信息，可以保存在页头，也可由表的元数据推算得到。 页身从前向后存储数据，从后向前存储槽目录，槽目录存储记录的字节偏移量。槽目录可以每2字节对应从0开始的自然数槽号，这样在通过槽号访问某槽时只需要O(1)时间，但在插入记录时最好在槽目录中从后向前优先利用无效槽号；也可以在槽目录中只存储有效槽号，不过在通过槽号访问某槽时需要遍历槽目录。某条记录的页号和槽号建议不要轻易修改，否则相关的索引也要修改。 删除记录时可能产生碎片空闲空间，在数据量较小时不处理也无妨。在真实数据库中会有程序定期清理碎片空间，使页内空闲空间尽量连续。 空闲空间管理 链表 与定长记录类似，页面的空闲空间最大为 4096-64 字节，可以按照一定字节数 (如：32字节) 为单位将空闲空间大小分成若干个级别，每一级别维护一个链表。 页目录 可以保留一些页作为页目录而不作为数据页，页目录之间通过链表相连；每个页目录记录若干页的空闲空间大小。 大根堆二叉树 可以为每个表创建一个名为\"表ID_fsm\"的文件管理表的空闲空间。每个FSM页内为一棵大根堆二叉树，叶节点记录某页的空闲空间大小 (也可以将空闲空间大小分成256个级别，使每个节点仅占用1B)，非叶节点记录两个孩子中的较大值。这样，在需要一定空闲空间大小时，仅比较根节点即可判断表内是否有页面满足要求，然后沿二叉树逐级比较向下直到叶节点，即可找到合适的空闲页面。 如果页面较多，可以构建多级FSM页，高级FSM页的叶节点对应低级FSM页的根节点，且它们具有相同的值。 假设每个页面数据区大小为10B，则每个页面内可以构建出有4个叶节点的满二叉树；假设共有3级FSM页，例： 0 <-- page 0 at level 2 (root page) 0 <-- page 0 at level 1 0 <-- page 0 at level 0 1 <-- page 1 at level 0 2 <-- ... 3 1 <-- page 1 at level 1 4 5 6 7 8 9 假设命中了8号页内数据区偏移量为5的字节，由 n+⌊n/4+1⌋+⌊n/4^2+1⌋=8 解得 n=5，即8号页对应0级5号页；偏移量为5对应FSM页内1号叶节点。由 5*5+1=26 知对应表内26号页。 大根堆二叉树也可以参考PostgreSQL中相应说明。 last update at: 2021/9/9 13:31:51 author: 孙昭言 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-2/api.html","title":"2.4 对外提供的接口","level":"2.2.4","keywords":[],"body":"2.4 对外提供的接口 class RecordHandler { public: RecordHandler (); // 构造函数 ~RecordHandler (); // 析构函数 RC CreateFile (const char *fileName); // 创建文件 RC DestroyFile (const char *fileName); // 删除文件 RC OpenFile (const char *fileName); // 通过缓存管理模块打开文件，并获取其句柄 RC CloseFile (); // 关闭fileID对应文件 RC GetRecord (const RID &rid, char *&pData); // 通过页号和槽号访问记录后，相应字节序列可以通过pData访问 RC DeleteRecord (const RID &rid); // 删除特定记录 RC InsertRecord (const RID &rid, const char *pData); // 将字节序列pData插入特定位置 RC UpdateRecord (const RID &rid, const char *pData); // 将特定位置记录更新为字节序列pData }; last update at: 2021/9/9 19:00:09 author: 孙昭言 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-3/intro.html","title":"3.1 索引管理模块概述","level":"2.3.1","keywords":[],"body":"3.1 索引管理模块概述 索引是这样的数据结构：它以一个或多个属性的值为输入，并能快速地定位具有该值的记录的位置。索引的属性（组）称为查找键。由于索引是表的附加结构，当表的内容发生变化时，DBMS必须同步更新该表的索引。由此可见，索引虽然有助于提高查询性能，但是索引本身也会带来存储和维护开销。与表一样，一个索引结构同样存储在一个页式文件中。 本节内容对应教材《数据库系统设计与原理(第2版)》（冯建华等，清华大学出版社）第8章：索引和散列。 记录的组织方式 关系 (表、索引) 是记录的集合，索引中 (关键字, 表页号, 表页内槽号) 的对应关系也可以作为记录存储。以0.2提到的course表的主键id的索引为例，其一行可以分为三个定长列：(id, 表页号，表页内槽号)。 记录在关系中可以有不同的组织方式： 堆文件组织：一条记录可以放在文件中的任何地方，只要那里有足够的空间存放这条记录，记录间不用考虑先后顺序的。第2节中说明的表按照这种方式组织。 顺序文件组织：记录根据其\"查找键\"的值顺序存储。顺序索引按照这种方式组织。 散列文件组织：在每条记录的某个/些属性上计算一个散列函数，根据散列的结果来确定将记录放到文件的哪个页面中。散列索引按照这种方式组织。 索引的元数据 索引的元数据与表的元数据基本相同，可以用相同的方式处理，不过要注意存储使用索引的表。 last update at: 2021/9/9 13:31:51 author: 孙昭言 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-3/btree.html","title":"3.2 索引结构-B树和B+树","level":"2.3.2","keywords":[],"body":"3.2 索引结构-B树和B+树 B树在先修课程《数据结构》中做过讲解，这里不再赘述。索引结构中我们重点介绍B+树。 B+树概述 m 阶B+树具有如下特征： 每个结点的关键字个数与孩子个数相等，所有非最下层的结点的关键字是对应子树上的最大关键字。 除根结点以外，每个内部结点的孩子数属于 [(m+1)/2, m]。 最下层结点（叶结点）包含了全部“键-值”对，叶结点可以按照键值从小到大连成单向或双向的链表。 在数据库索引中，每页作为一个结点，是否叶结点、叶结点链表等数据可以存储在页头中。非叶结点要存储若干个 (关键字, 孩子页号) 结构，叶结点要存储若干个 (关键字, 表页号, 表页内槽号) 结构，这种结构可以像表内一条记录一样存储。 查找 给定待查找的关键字，对每个结点找到不小于该关键字的第一项。从根结点开始对每个途经结点重复上述过程，并选择键值对应孩子页为下一个查找结点，从而在索引中找到该关键字的下界所在的叶结点。查找某个关键字范围 [a, b] 内的记录可以先找到关键字 a，然后沿叶结点链表顺序查找，直到某个叶结点存在大于b的关键字。 插入 给定待插入记录的关键字，可以插入到其下界所在的叶结点。如果叶结点最大键值改变，可能需要逐级更新父结点的键值。如果某结点发生上溢，则将其分裂为两个分支数相近的结点，都作为该结点父结点的子结点，父结点也要处理可能的上溢；如果该结点为根结点，则需要创建新的根结点作为父结点。 删除 给定某关键字（范围），查找其下界所在的叶结点，然后沿叶结点链表顺序扫描直到完成删除。如果叶结点最大键值改变，可能需要逐级更新父结点的键值。如果某结点发生下溢，如果其为根结点，其子结点在某些情况下可能成为新的根结点；如果其左/右兄弟有多余的孩子结点，可以过继给它；否则可以将其与左/右兄弟合并成一个结点，删除或更新父结点的关键字，父结点也要处理可能的下溢。 更新 查找给定关键字直到恰好匹配表页号和槽号完成更新，索引结构保持不变。 last update at: 2021/9/9 13:31:51 author: 孙昭言 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-3/ds.html","title":"3.3 更多的索引结构（阅读内容）","level":"2.3.3","keywords":[],"body":"3.3 更多的索引结构（阅读内容） 散列表 散列表的两个要素是散列函数和桶数组，相关知识在先修课程《数据结构》中做过讲解，这里不再赘述。散列表索引的桶数组存储在页式文件中。 静态散列表 桶的总数不变。i 号桶对应 i 号页，桶满后以链表的形式添加新页。 动态散列表 动态散列表可以根据记录总数调整桶的总数。其做出的改进如下： 增加了一个间接层，用一个指向页面的指针数组（桶地址表）而非页面数组来表示桶数组。 指针数组能动态增长，且数组长度总是2的幂，因此数组每增长一次，桶的数量就翻倍。 并非每个桶都单独拥有一个页面。如果多个桶的记录只需一个页面就能放下，那么这些桶可能共享一个页面，即多个桶指针指向同一个页面。 散列函数 h 为每个键计算出一个长度为N的二进制序列，但是在某一时刻，这个序列中只有前 i 位 (i≤N) 被使用，此时桶的数量为 2^i 个。 插入关键字为 K 的记录时，根据散列函数计算 h(K)，取出该二进制序列的前 i 位，并根据桶地址表找到桶数组中相对应的页面 j。如果页面已满，可能出现两种情况： 桶地址表中有多个表项指向该页面，此时不需要扩大桶地址表就能分裂页面。分配一个新的页面 n，调整桶地址表中原来指向页面 j 的表项，其中一半指向新创建的页面 n；重新散列页面j中的各条记录，将其分配到页面 j 或页面 n 中，并再次尝试插入新记录。如果插入失败，则需要继续进行页面分裂。 如果桶地址表中只有一个表项指向页面 j，此时分裂该页，需要使桶地址表的大小翻倍，以容纳由于分裂而产生的两个桶指针。桶地址表扩展后，原表中的每个表项都被两个表项替代，且这两个表项都包含和原始表项一样的指针，所以也应该有两个表项指向页面 j。此时，分配一个新的页面 n，并让第二个表项指向页面 n。将原页面j中的各条记录重新散列，根据前 i+1 位来确定该记录是放在页面 j 中还是页面 n 中，然后再次尝试插入新记录。如果插入失败，则需要继续进行页面分裂。 其它索引结构 非传统关系型数据库也会用到跳转表 (Skiplist)、布隆过滤 (Bloom Filter) 等数据结构，这些内容已经超出本课程范围。 last update at: 2021/9/9 13:31:51 author: 孙昭言 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-3/api.html","title":"3.4 对外提供的接口","level":"2.3.4","keywords":[],"body":"3.4 对外提供的接口 class IndexScan { public: IndexScan (); // 构造函数 ~IndexScan (); // 析构函数 RC GetNextEntry (RID &rid); // 类似于Python中的迭代器，不断调用获取下一个记录的位置 }; // 基础功能中，索引关键字只要求单列整型 class IndexHandler { public: IndexHandler (); // 构造函数 ~IndexHandler (); // 析构函数 RC CreateIndex (const char *fileName); // 创建索引 RC DestroyIndex (const char *fileName); // 删除索引 RC OpenIndex (const char *fileName); // 通过缓存管理模块打开索引，并获取其句柄 RC CloseIndex (); // 关闭索引 RC Search (int lowerBound, int upperBound, IndexScan &indexScan); // 查找某个范围内的记录，结果通过迭代器访问 RC DeleteRecord (int lowerBound, int upperBound); // 删除某个范围内的记录 RC InsertRecord (int key, const RID &rid); // 插入某个记录的位置 RC UpdateRecord (int oldKey, const RID &oldRid, int newKey, const RID &newRid); // 更新特定记录的关键字或位置 }; last update at: 2021/9/9 19:00:09 author: 孙昭言 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-4/4-1-overview.html","title":"4.1 概述","level":"3.1.1","keywords":[],"body":"4.1 概述 查询处理指的是将查询语句转化为查询结果的过程，主要包含三个步骤： 解析器对查询语句进行语法分析，转化为语法树。 优化器首先将语法树转化为关系代数表达式树，我们将其称为逻辑查询计划树。进一步，根据数据的统计信息(如表的大小、是否有索引等)，为逻辑查询的每一步指定操作的顺序、使用的算法、访问数据的方式等，转化为物理查询计划树。 执行器在数据库上执行查询计划，并返回查询结果。 下图展示了一条 SQL 语句和其对应的逻辑查询计划树，逻辑查询计划树每个节点表示一个关系代数运算。但是，每个关系代数运算存在不同的操作方式，如扫描表时是否使用索引，表的连接采用什么算法等。我们需要根据数据库的统计信息，如索引、记录数量等，为每个关系代数运算选择最优的算法。本章主要介绍扫描算法和连接算法。 last update at: 2021/8/25 14:33:58 author: 李文博 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-4/4-2-scan.html","title":"4.2 扫描算法","level":"3.1.2","keywords":[],"body":"4.2 扫描算法 表的扫描是物理查询计划中最基本的操作，如对于 SELECT * FROM A; 这样一条简单的 SQL 查询，我们只需要将表A扫描一遍，输出表A的所有记录即可。 而大部分情况下，查询会包含一个谓词，如 SELECT * FROM A WHERE a < 10，这时我们在扫描表A的同时，还需要判断表A的每条记录是否符合谓词条件。对于这类查询，表的扫描算法主要有两种： 顺序扫描 (Sequential Scan)。最基本的扫描算法，扫描一张表的所有记录，判断记录是否符合选择条件，符合则将其加入查询结果，不符合则丢弃。 索引扫描 (Index Scan)。如果选择条件对应的列上有索引，便可以利用索引来得到符合条件的记录，避免全表扫描的过程。 last update at: 2021/8/25 14:33:58 author: 李文博 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-4/4-3-join.html","title":"4.3 连接算法","level":"3.1.3","keywords":[],"body":"4.3 连接算法 连接运算是关系代数中一个重要操作，也往往是最耗时的操作。本节我们仅讨论两表连接算法，且仅讨论等值连接，即形如 SELECT * FROM A,B WHERE A.a=B.b 查询的连接算法。 嵌套循环连接 (Nested Loop Join) 嵌套循环连接是两表连接最基本的算法，算法描述如下： for each row r1 in t1 { for each row r2 in t2 { if r1, r2 satisfies join conditions join r1, r2 } } 嵌套循环连接存在多种改进方法，如数据库可以每次读取一个 block，减少 I/O 请求次数。考虑记录获取方式，即可得到基于块的嵌套循环连接算法 (Block Nested Loop Join)，算法描述如下： for each block b1 of t1 { if b1 not in memory read b1 block b1 into memory for each row r1 in block b1 { for each block b2 of t2 { if b2 not in memory read block b2 into memory for each row r2 in b2 { if r1, r2 satisfies join conditions join r1, r2 } } } } 此外，如果内表在连接属性上有索引，则可以利用索引加速内循环，得到基于索引的循环连接算法 (Index Nested Loop Join)，有效提高连接效率。 排序归并连接 (Sort-Merge Join) 先将要连接的两个表在连接属性上排序，随后对排序后的表进行连接，算法描述如下： sort t1, t2 on join keys cursor_1 <- t1, cursor_2 <- t2 while cursor_1 and cursor_2: if cursor_r < cursor_2: increment cursor_1 if cursor_1 > cursor_2: increment cursor_2 if cursor_1 == cursor_2: Join cursor_1, cursor_2 如果两张表在连接前已经在连接属性上排好序，则可以省去排序操作。此外，排序归并连接算法的输出结果也是在连接属性上排好序的，如果查询在连接属性上有 order by 子句，排序归并连接算法便可以直接给出有序结果。 哈希连接 (Hash Join) 对一张表进行哈希运算建立哈希表，哈希表的 key 为连接属性。对另一张表的每条记录，用哈希函数求得连接属性上的值，映射到哈希表上即可得到要连接的记录，算法描述如下： build hash table HT for t1 for each row r2 in t2: if h(r2) in HT: join t1, t2 哈希连接算法效率较高，算法复杂度为 O(T1+T2)O(T1+T2)O(T1+T2)​，T1T1T1​ 和 T2T2T2​ 分别表示两张表记录的个数。但是哈希连接仅支持等值连接，且哈希表需要占用较大的内存空间，如果哈希表大小超出内存空间限制，则需要将哈希表写入临时文件。 last update at: 2021/8/25 14:33:58 author: 李文博 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-4/4-4-execution.html","title":"4.4 查询执行","level":"3.1.4","keywords":[],"body":"4.4 查询执行 目前仅讨论了单个关系运算如何执行，下面需要研究如何执行包含多个运算的查询计划树。 物化 最简单直观的想法是自底向上执行查询计划树，依次执行每个算子，每次执行的临时结果存储到内存或磁盘上，下一个算子在临时结果的基础上继续进行，这种执行策略称为物化。 物化方法的策略简单，但会产生大量的中间结果，占据磁盘和内存空间，且查询过程中需要多次访问磁盘，效率较低。 流水线 执行查询计划的另一种方法是同时进行多个运算，一个运算产生的结果直接传递给使用这个结果的下一个运算，不需要将中间结果存储到磁盘，这种方法称为流水线。 流水线中的每个操作可以由一个迭代算子来实现，每个迭代算子提供 Init 和 Next 接口。调用 Init 后，每次调用 next 返回该操作输出的下一条结果。同时迭代算子自身需要维护迭代状态，使得每次调用 next 返回正确的结果。 last update at: 2021/8/25 14:33:58 author: 李文博 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-4/4-5-api.html","title":"4.5 对外提供的接口","level":"3.1.5","keywords":[],"body":"4.5 对外提供的接口 class AbstractExecutor { void Init() = 0; bool Next(RID *rid) = 0; } class SeqScanExecutor: AbstractExecutor { void Init(); bool Next(RID *rid); } class IndexScanExecutor: AbstractExecutor { void Init(); bool Next(RID *rid); } class NestedLoopJoinExecutor: AbstractExecutor { void Init(); bool Next(RID *rid); } class SortMergeJoinExecutor: AbstractExecutor { void Init(); bool Next(RID *rid); } class HashJoinExecutor: AbstractExecutor { void Init(); bool Next(RID *rid); } last update at: 2021/9/9 19:00:09 author: 李文博 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-5/5_1_intro.html","title":"5.1 概述","level":"3.2.1","keywords":[],"body":"5.1 解析器概述 在数据库系统中，解析器与执行器的作用紧密相关。当数据库系统需要执行一条查询执行时，需要通过结构化查询语言（SQL）描述这一查询过程传递给解析器。解析器的主要功能在于解析输入的SQL语句并将其转化为一套高效的物理执行计划交由执行器完成。内部的工作流程可以概括为3个部分： 词法语法分析：SQL语句到抽象语法树 逻辑优化：抽象语法树到逻辑计划树 物理优化：逻辑计划树到物理执行计划 经过词法和语法分析，SQL语句可以转化为抽象语法树，这一部分是编译原理课程的主要内容，期间不需要考虑数据库系统的设计和底层存储结构等任何与数据库系统实现相关的内容。所以这一部分不作为本课程关注的重点。根据我们所给出的语法文件，直接利用antlr的访问者模式可以比较轻松地完成这一步转化工作。 数据库解析器的特色在于其抽象语法树的后续处理过程，与编译器和解释器不同，此处不会结合系统和虚拟机特性转化为某种编码格式，而是需要结合数据库的一些统计信息和存储结构，在可能面临的很多种执行方案中规划出一套相对较优的实际物理执行计划并传递给执行器完成这一工作。这一部分包含了逻辑优化和物理优化两个过程，这一部分将成为各位同学思考的重点。 last update at: 2021/8/25 14:33:58 author: 董昊文 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-5/5_2_sql.html","title":"5.2 SQL简介","level":"3.2.2","keywords":[],"body":"5.2 SQL语法简介 结构化查询语言(Structured Query Language)简称SQL，是一种数据库查询和程序设计语言，用于存取数据以及查询、更新和管理关系数据库系统；同时也是数据库脚本文件的扩展名。SQL是一门 ANSI 的标准计算机语言，用来访问和操作数据库系统。虽然作为一种数据库语言的基准，但是工业界数据库厂商大多都在SQL基准基础之上进行了一定程度的变化和拓展，导致了当今存在了大量不同版本的SQL文法规范。本次实验任务中，同学们仅需要重点关注于SQL语言中有关于数据操作语言（DML）和数据定义语言（DDL）的部分重点文法结构。 所有需要支持的文法已经在sql.g4文件中给出，文法对应的功能可以参阅文法手册。 由于SQL语句转抽象语法树的部分是编译原理课程已经充分研究的内容，所以第一个转化阶段不作为本次实验的重点内容，可以直接基于给出的文法文件利用antlr的访问者模式生成这一部分代码。解析器部分重点的实验内容为逻辑优化和物理优化的过程。 考虑到部分同学可能没有接触过编译原理课程的相关内容，在此给出利用antlr生成C++版本编译器基本代码的流程。 配置JAVA环境 访问www.antlr.org/download.html，下载最新版的的antlr4.jar文件 通过如下指令可以生成最基本的C++版本编译器代码java -jar <antlr4.jar文件路径> -Dlanguage=Cpp <sql.g4语法文件路径> -visitor -no-listener -o <生成代码文件输出路径> 通过继承BaseVisitor可以在编译器中实现自定义的编译过程，从而实现编译器的设计 在使用自动生成的antlr4代码时，需要下载对应版本的antlr4-runtime.h库文件并利用编译配置文件正确包含这一头文件 解析SQL过程中使用生成代码的方式 ```(c++)include include \"antlr4-runtime.h\" // 包含你完成的Visitor类 include \"YourVisitor.h\" using namespace antlr4; // 返回类型根据你的visitor决定 auto parse(std::String sSQL) { // 解析SQL语句sSQL的过程 // 转化为输入流 ANTLRInputStream sInputStream(sSQL); // 设置Lexer SQLLexer iLexer(&sInputStream); CommonTokenStream sTokenStream(&iLexer); // 设置Parser SQLParser iParser(&sTokenStream); auto iTree = iParser.program(); // 构造你的visitor YourVisitor iVisitor{/YourVisitor的构造函数/}; // visitor模式下执行SQL解析过程 // --如果采用解释器方式可以在解析过程中完成执行过程（相对简单，但是很难进行进一步优化，功能上已经达到实验要求） // --如果采用编译器方式则需要生成自行设计的物理执行执行计划（相对复杂，易于进行进一步优化，希望有能力的同学自行调研尝试） auto iRes = iVisitor.visit(iTree); return iRes; } ``` 如果同学们没有接触过antlr，也可以使用自己熟悉的其他编译代码生成工具，但是需要保证能够支持要求的文法标准。 last update at: 2021/9/9 21:08:27 author: 董昊文 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-5/5_3_logic.html","title":"5.3 逻辑优化","level":"3.2.3","keywords":[],"body":"5.3 逻辑优化：抽象语法树到逻辑计划树（选做） 查询优化器在逻辑优化阶段主要解决的问题是：如何找出SQL语句的等价变换形式，使SQL执行更高效；一般可以使用代数优化的方式完成这一过程。代数优化是通过关系代数中一些等价变化的方式调整原始的抽象语法树结构，使其变化为执行过程上更为简洁高效的逻辑计划树的形式。主要是一些基于规则的固定转化模式，逻辑优化过程基于如下的经验规则： 尽早进行选择运算，这样可以尽早降低运算数据的规模 合并同表的多个选择和投影运算，减少表的扫描次数 合并投影运算和其他双目运算（笛卡尔积，等值连接，并集差集），减少表的扫描次数 合并选择运算与笛卡尔积，避免直接计算笛卡尔积 提取公共子表达式，重复使用 基于上述的经验规则，常用的变化包括如下几类： 列裁剪：运算过程中仅保留必要的列，忽略其余列，降低数据传输开销。 谓词下推：将查询语句中的过滤表达式计算尽可能下推到距离数据源最近的地方，以尽早完成数据的过滤，进而显著地减少数据传输或计算的开销。 子查询合并：在语义等价条件下，多个子查询可以合并成一个子查询，这样多次表扫描，多次连接减少为单次表扫描和单次连接。 谓词重写：利用一些等价规则将IN、OR、LIKE、BETWEEN、AND等谓词进行等价转化。 条件化简：对于WHERE、HAVING等条件进行化简，例如常量传递和不等式变化等。 逻辑优化部分的代码实现需要一定编译原理的课程基础以及较高的编程能力支持，所以这一部分可能对于部分没有接触过编译原理知识的同学造成过大的负担。所以逻辑优化的内容仅作为选做内容，希望各位对于数据库系统感兴趣的同学可以自行探索并实现这一部分的内容。 last update at: 2021/9/1 17:03:01 author: 董昊文 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"chapter-5/5_4_physic.html","title":"5.4 物理优化","level":"3.2.4","keywords":[],"body":"5.4 物理优化：查询计划树到物理执行计划（选做） 代数优化改变查询语句中操作的次序和组合，但不涉及底层的存取路径。物理优化就是要选择高效合理的操作算法或存取路径，求得优化的查询计划，达到查询优化的目标。 查询优化器在物理优化阶段，主要解决的问题包括： 单表扫描过程应该选择何种算法？ 两表连接使用何种连接算法？ 多表连接如何确定连接算法顺序？ 查询计划的规划时间是否可接受？ 可以选择基于规则的启发式优化或基于代价估算的优化。基于规则的启发式算法一般相对简单，优化效果一般但是速度较快，适合于解释执行的系统，查询优化和查询执行同时进行。编译执行的方式则是先进行编译优化后整体执行，查询优化和查询执行分离，此时使用基于代价估算的优化更容易获得更好的优化效果，但是可能会面临执行计划的选择空间很大，优化时间开销过高的问题。而将两者结合，先使用启发式算法限制候选空间，对于候选空间内的方案进行代价估计，这样可以在较短时间内获得一个相对较优的执行计划。 这一部分是数据库系统的核心内容之一，物理计划的选择对于查询执行速度的影响是十分巨大的。很多情况下，一个不合理的的物理执行计划将会造成多个数量级的时间和空间开销。但是考虑到物理优化与底层系统设计有很强关联性，同时较为经典的物理计划选择算法都具有一定的实现难度。所以物理优化部分仅作为选做内容，如果各位同学希望对于这一部分进行深入研究，可以自行调研相关的经典文献并进行实现。 last update at: 2021/9/1 17:03:01 author: 董昊文 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"extra/faq.html","title":"FAQ","level":"5.1","keywords":[],"body":"FAQ 这里收集了一些近年来本实验相关的常见问题，我们会在每年课程进行中动态更新本节。 [success] 参考实现的页式文件系统似乎有 bug，同时打开多个文件会出现混乱？ 在参考代码 testfilesystem.cpp 中展示了正确用法：启动系统时要调用静态成员函数 MyBitMap::initConst()，否则哈希值计算错误可能导致多个文件被视为同一个。 [success] 批量导入数据时有性能要求吗？ 没有。批量导入数据的功能仅仅为了便于测试之用，这并不作为数据库正式功能，你能在验收当天导入即可:D。现场验收时可能会提问实现细节。 [success] 会考查 SQL 语法错误的输入报错吗？ 不会。可能会考查破坏完成性约束等异常输入，但是输入一定是能通过 parser 的。 [success] 最终测试时会有多大数据规模？ （最后更新于 2020秋）单数据库测试，其总数据量小于 1GB，单表列数不超过 10，表数不超过 8，单列最大长度不超过 2048B。 last update at: 2021/9/9 20:49:25 author: 饶淙元 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "},{"url":"extra/files.html","title":"附件","level":"5.2","keywords":[],"body":"附件 如下是本实验提供的附件： 页式文件系统参考实现: filesystem.zip Anltr 文法文件: SQL.g4 last update at: 2021/9/9 21:29:00 author: 饶淙元 var discussion = document.getElementById('my-comment'); var script = document.createElement('script'); script.src = 'https://utteranc.es/client.js'; script.setAttribute('repo', 'thu-db/dbs-tutorial'); script.setAttribute('issue-term', \"pathname\"); script.setAttribute('theme', 'github-light'); script.setAttribute('crossorigin', 'anonymous'); discussion.appendChild(script); "}]